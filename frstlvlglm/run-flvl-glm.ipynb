{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smooth data and fit first level GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K. Garner, 2022  \n",
    "This code will smooth the data and fit a first level GLM to each participant's fmri data.  \n",
    "Assumptions:  \n",
    "Data is BIDS enough.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220414-16:52:21,132 nipype.utils WARNING:\n",
      "\t A newer version (1.7.1) of nipy/nipype is available. You are using 1.5.0\n"
     ]
    }
   ],
   "source": [
    "from bids.layout import BIDSLayout\n",
    "#from nipype.interfaces import afni \n",
    "from nipype.interfaces.io import BIDSDataGrabber, DataFinder, DataSink, DataGrabber\n",
    "import nipype.pipeline as pe\n",
    "import nipype as ni\n",
    "from nipype.interfaces.utility import Function\n",
    "import nipype.interfaces.fsl.maths as fsl\n",
    "from nipype.interfaces import spm as spm\n",
    "from nipype.algorithms import modelgen as mgen\n",
    "from nipype.algorithms.misc import Gunzip \n",
    "import pandas as pd\n",
    "import os, re, json\n",
    "# https://nipype.readthedocs.io/en/0.11.0/users/spmmcr.html\n",
    "\n",
    "matlab_cmd = '/opt/spm12-r7219/run_spm12.sh /opt/matlabmcr-2010a/v713/ script'\n",
    "spm.SPMCommand.set_mlab_paths(matlab_cmd=matlab_cmd, use_mcr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define source data location and establish workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/bids/layout/models.py:102: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "basedir = '/scratch/qbi/uqkgarn1/data/'\n",
    "layout = BIDSLayout(basedir)\n",
    "subs = layout.get_subjects()\n",
    "\n",
    "glm = pe.Workflow(name='glms') # workflow to run the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data grabbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = pe.Node(DataGrabber(infields= ['sub'], \n",
    "                         outfields=['func', 'motion', 'onsets', 'bjson', 'mask']), \n",
    "                         name='data-grabber')\n",
    "dg.inputs.base_dir = '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/'\n",
    "\n",
    "\n",
    "dg.inputs.sort_filelist = True\n",
    "dg.inputs.template='*'\n",
    "dg.inputs.template_args = {'func': [['sub', 'sub']],\n",
    "                           'motion':[['sub', 'sub']],\n",
    "                           'onsets':[['sub', 'sub']],\n",
    "                           'bjson':[['sub', 'sub']],\n",
    "                           'mask':[['sub', 'sub']]}\n",
    "dg.inputs.field_template = {'func':   '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-%s/ses-02/func/sub-%s_*_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
    "                            'motion': '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-%s/ses-02/func/sub-%s_ses-02_task-attlearn_run-*_desc-motion-physregress_timeseries.txt',\n",
    "                            'onsets': '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-%s/ses-02/beh/sub-%s_ses-02_task-attlearn_run-*_desc-glm-onsets.json',\n",
    "                            'bjson':  '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-%s/ses-02/func/sub-%s_ses-02_task-attlearn_run-*_space-MNI152NLin2009cAsym_desc-preproc_bold.json',\n",
    "                            'mask':   '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-%s/ses-02/func/sub-%s_ses-02_task-attlearn_run-*_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220414-16:52:23,747 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"data-grabber\" in \"/tmp/tmpovcr3oi_/data-grabber\".\n",
      "220414-16:52:23,753 nipype.workflow INFO:\n",
      "\t [Node] Running \"data-grabber\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220414-16:52:23,763 nipype.workflow INFO:\n",
      "\t [Node] Finished \"data-grabber\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "bjson = ['/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.json', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.json', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-3_space-MNI152NLin2009cAsym_desc-preproc_bold.json']\n",
       "func = ['/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-3_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz']\n",
       "mask = ['/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-1_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-2_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-3_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz']\n",
       "motion = ['/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-1_desc-motion-physregress_timeseries.txt', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-2_desc-motion-physregress_timeseries.txt', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/func/sub-01_ses-02_task-attlearn_run-3_desc-motion-physregress_timeseries.txt']\n",
       "onsets = ['/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/beh/sub-01_ses-02_task-attlearn_run-1_desc-glm-onsets.json', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/beh/sub-01_ses-02_task-attlearn_run-2_desc-glm-onsets.json', '/scratch/qbi/uqkgarn1/data/derivatives/fmriprep/sub-01/ses-02/beh/sub-01_ses-02_task-attlearn_run-3_desc-glm-onsets.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.inputs.sub = subs[0]\n",
    "res = dg.run()\n",
    "res.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pe.Node(ni.IdentityInterface(fields=['sub', 'sub']), name = 'info')\n",
    "info.iterables = [('sub', ['01'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSubPath(full_file_path):\n",
    "    # function to split filepath into constituent parts, then print string to add as input to DataSink for the \n",
    "    # container string\n",
    "    # given the full filepath, this extracts the subj/ses folder names for input\n",
    "    # into DataSink\n",
    "    # Args\n",
    "    # -- full_file_path: cell of file names, any one of the data grabber outputs should work\n",
    "    # Returns\n",
    "    # -- string of the form 'sub'0x/ses-0x'\n",
    "    import os\n",
    "    import re\n",
    "    fname = os.path.normpath(full_file_path[0])\n",
    "    l = fname.split(os.sep)\n",
    "    sub = [s for s in l if re.search('sub', s)][0]\n",
    "    ses = [s for s in l if re.search('ses', s)][0]\n",
    "    name = [sub, ses]\n",
    "    name = '/'.join(name)\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasink node for data saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pe.Node(DataSink(), name='sink-stuff')\n",
    "ds.inputs.base_directory = \"/scratch/qbi/uqkgarn1/data/derivatives/spm/\"\n",
    "substitutions = [('_sub_([0-9]*)', '')]\n",
    "ds.inputs.regexp_substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get design info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOnsetsJson(input_files):\n",
    "    # reads the onsets for GLM from each run, and puts together as a bunch, ready for use in spm/model def\n",
    "    # Args:\n",
    "    # -- input_files [cell list of filenames] output as 'onsets' from datagrabber\n",
    "    # Returns\n",
    "    # a Bunch of dim n runs, containing the fields 'conditions', 'onsets', 'durations'\n",
    "    from nipype.interfaces.base import Bunch\n",
    "    import json\n",
    "    prt_output = [] #prt=protocol\n",
    "    count = 0\n",
    "    for f in input_files: \n",
    "        count = count + 1\n",
    "        with open(f, \"r+\") as file:\n",
    "            data = json.load(file)\n",
    "            prt_output.insert(count, \n",
    "                              Bunch(conditions=data['names'],\n",
    "                                    onsets=data['onsets'],\n",
    "                                    durations=data['durations']))\n",
    "    return prt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now a node to use the getOnsetsJson function in the work flow\n",
    "get_onsets = pe.Node(Function(input_names = ['input_files'],\n",
    "                              output_names = ['prt_output'],\n",
    "                              function = getOnsetsJson),\n",
    "                     name = 'get_prt_onsets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some unzipping modules so that spm can handle the images\n",
    "\n",
    "Note: I opted to create 2 to avoid output conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip_func = pe.MapNode(Gunzip(), name='gunzipfunc', iterfield=['in_file'])\n",
    "gunzip_mask = pe.MapNode(Gunzip(), name='gunzipmask', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smooth the functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = pe.Node(spm.Smooth(), name='smooth')\n",
    "smooth.inputs.fwhm = [2, 2, 2]  # play with this for sub 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grab the TR for the model specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTRJson(input_files):\n",
    "    # extracts the TR in seconds from one of the json files accompanying the T2 images\n",
    "    # Args\n",
    "    # -- input_files: cell list of json files for bold images (bjson from data grabber)\n",
    "    # Returns\n",
    "    # -- TR [numeric]: TR is seconds\n",
    "    import json\n",
    "    with open(input_files[0], \"r+\") as file:\n",
    "            data = json.load(file)\n",
    "            TR = data['RepetitionTime'] \n",
    "    return TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tr = pe.Node(Function(input_names=['input_files'],\n",
    "                          output_names=['TR'],\n",
    "                          function=getTRJson),\n",
    "                 name='get_TR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specify glm, generate design matrix and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spec = pe.Node(mgen.SpecifySPMModel(concatenate_runs=False,\n",
    "                                         input_units='secs',\n",
    "                                         output_units='secs',\n",
    "                                         high_pass_filter_cutoff=128),\n",
    "                     name=\"modelspec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_design = pe.Node(spm.Level1Design(bases={'hrf': {'derivs': [1, 1]}},\n",
    "                                 timing_units='secs',\n",
    "                                 model_serial_correlations='FAST'),\n",
    "                         name=\"level1design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate = pe.Node(spm.EstimateModel(estimation_method={'Classical': 1},\n",
    "                                     write_residuals=False),\n",
    "                                     name=\"estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect workflow and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220414-16:53:48,153 nipype.workflow INFO:\n",
      "\t Workflow glms settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "220414-16:53:48,175 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "220414-16:53:48,176 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.data-grabber\" in \"/tmp/tmpovcr3oi_/data-grabber\".\n",
      "220414-16:53:48,177 nipype.workflow INFO:\n",
      "\t [Node] Outdated cache found for \"glms.data-grabber\".\n",
      "220414-16:53:48,182 nipype.workflow INFO:\n",
      "\t [Node] Running \"data-grabber\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "220414-16:53:48,189 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.data-grabber\".\n",
      "220414-16:53:48,189 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.get_TR\" in \"/tmp/tmpfr3jhwbj/glms/_sub_01/get_TR\".\n",
      "220414-16:53:48,194 nipype.workflow INFO:\n",
      "\t [Node] Running \"get_TR\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "220414-16:53:48,198 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.get_TR\".\n",
      "220414-16:53:48,199 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.gunzipmask\" in \"/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask\".\n",
      "220414-16:53:48,204 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipmask0\" in \"/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask0\".\n",
      "220414-16:53:48,207 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipmask0\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:53:48,235 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipmask0\".\n",
      "220414-16:53:48,236 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipmask1\" in \"/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask1\".\n",
      "220414-16:53:48,239 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipmask1\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:53:48,270 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipmask1\".\n",
      "220414-16:53:48,271 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipmask2\" in \"/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask2\".\n",
      "220414-16:53:48,274 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipmask2\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:53:48,315 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipmask2\".\n",
      "220414-16:53:48,318 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.gunzipmask\".\n",
      "220414-16:53:48,318 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.gunzipfunc\" in \"/tmp/tmpns9yjtb8/glms/_sub_01/gunzipfunc\".\n",
      "220414-16:53:48,324 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc0\" in \"/tmp/tmpns9yjtb8/glms/_sub_01/gunzipfunc/mapflow/_gunzipfunc0\".\n",
      "220414-16:53:48,326 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc0\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:53:50,225 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipfunc0\".\n",
      "220414-16:53:50,228 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc1\" in \"/tmp/tmpns9yjtb8/glms/_sub_01/gunzipfunc/mapflow/_gunzipfunc1\".\n",
      "220414-16:53:50,231 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc1\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:54:07,680 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipfunc1\".\n",
      "220414-16:54:07,684 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"_gunzipfunc2\" in \"/tmp/tmpns9yjtb8/glms/_sub_01/gunzipfunc/mapflow/_gunzipfunc2\".\n",
      "220414-16:54:07,688 nipype.workflow INFO:\n",
      "\t [Node] Running \"_gunzipfunc2\" (\"nipype.algorithms.misc.Gunzip\")\n",
      "220414-16:54:25,238 nipype.workflow INFO:\n",
      "\t [Node] Finished \"_gunzipfunc2\".\n",
      "220414-16:54:25,243 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.gunzipfunc\".\n",
      "220414-16:54:25,243 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.smoooooth\" in \"/tmp/tmphf27avfk/glms/_sub_01/smoooooth\".\n",
      "220414-16:54:25,252 nipype.workflow INFO:\n",
      "\t [Node] Running \"smoooooth\" (\"nipype.interfaces.spm.preprocess.Smooth\")\n",
      "220414-17:02:21,140 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.smoooooth\".\n",
      "220414-17:02:21,141 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.get_prt_onsets\" in \"/tmp/tmpnbzk01mx/glms/_sub_01/get_prt_onsets\".\n",
      "220414-17:02:21,147 nipype.workflow INFO:\n",
      "\t [Node] Running \"get_prt_onsets\" (\"nipype.interfaces.utility.wrappers.Function\")\n",
      "220414-17:02:21,153 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.get_prt_onsets\".\n",
      "220414-17:02:21,154 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.modelspec\" in \"/tmp/tmpdjteoe4t/glms/_sub_01/modelspec\".\n",
      "220414-17:02:21,172 nipype.workflow INFO:\n",
      "\t [Node] Running \"modelspec\" (\"nipype.algorithms.modelgen.SpecifySPMModel\")\n",
      "220414-17:02:25,281 nipype.workflow INFO:\n",
      "\t [Node] Finished \"glms.modelspec\".\n",
      "220414-17:02:25,282 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"glms.level1design\" in \"/tmp/tmpczqyhzqk/glms/_sub_01/level1design\".\n",
      "220414-17:02:25,286 nipype.workflow ERROR:\n",
      "\t Node level1design.a0 failed to run on host inode2.hpc.dc.uq.edu.au.\n",
      "220414-17:02:25,287 nipype.workflow ERROR:\n",
      "\t Saving crash info to /scratch/qbi/uqkgarn1/imaging_cert_value_7T_pipeline/frstlvlglm/crash-20220414-170225-uqkgarn1-level1design.a0-b45c145a-02f1-4b2c-a030-6e01d4c0348f.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/interfaces/base/traits_extension.py\", line 129, in validate\n",
      "    value = Path(value)  # Use pathlib's validation\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/pathlib.py\", line 1001, in __new__\n",
      "    self = cls._from_parts(args, init=False)\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/pathlib.py\", line 656, in _from_parts\n",
      "    drv, root, parts = self._parse_args(args)\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/pathlib.py\", line 640, in _parse_args\n",
      "    a = os.fspath(a)\n",
      "TypeError: expected str, bytes or os.PathLike object, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 46, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 486, in run\n",
      "    self._get_hashval()\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 538, in _get_hashval\n",
      "    self._get_inputs()\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 609, in _get_inputs\n",
      "    self.set_input(key, deepcopy(output_value))\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 302, in set_input\n",
      "    setattr(self.inputs, parameter, deepcopy(val))\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/interfaces/base/traits_extension.py\", line 330, in validate\n",
      "    value = super(File, self).validate(objekt, name, value, return_pathlike=True)\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/interfaces/base/traits_extension.py\", line 131, in validate\n",
      "    self.error(objekt, name, str(value))\n",
      "  File \"/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/traits/base_trait_handler.py\", line 75, in error\n",
      "    object, name, self.full_info(object, name, value), value\n",
      "traits.trait_errors.TraitError: The 'mask_image' trait of a Level1DesignInputSpec instance must be a pathlike object or string representing an existing file, but a value of \"['/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask0/sub-01_ses-02_task-attlearn_run-1_space-MNI152NLin2009cAsym_desc-brain_mask.nii', '/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask1/sub-01_ses-02_task-attlearn_run-2_space-MNI152NLin2009cAsym_desc-brain_mask.nii', '/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask2/sub-01_ses-02_task-attlearn_run-3_space-MNI152NLin2009cAsym_desc-brain_mask.nii']\" <class 'str'> was specified.\n",
      "\n",
      "Error setting node input:\n",
      "Node: level1design\n",
      "input: mask_image\n",
      "results_file: /tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/result_gunzipmask.pklz\n",
      "value: ['/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask0/sub-01_ses-02_task-attlearn_run-1_space-MNI152NLin2009cAsym_desc-brain_mask.nii', '/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask1/sub-01_ses-02_task-attlearn_run-2_space-MNI152NLin2009cAsym_desc-brain_mask.nii', '/tmp/tmp6_nv5x3u/glms/_sub_01/gunzipmask/mapflow/_gunzipmask2/sub-01_ses-02_task-attlearn_run-3_space-MNI152NLin2009cAsym_desc-brain_mask.nii']\n",
      "\n",
      "\n",
      "When creating this crashfile, the results file corresponding\n",
      "to the node could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220414-17:02:25,289 nipype.workflow INFO:\n",
      "\t ***********************************\n",
      "220414-17:02:25,289 nipype.workflow ERROR:\n",
      "\t could not run node: glms.level1design.a0\n",
      "220414-17:02:25,290 nipype.workflow INFO:\n",
      "\t crashfile: /scratch/qbi/uqkgarn1/imaging_cert_value_7T_pipeline/frstlvlglm/crash-20220414-170225-uqkgarn1-level1design.a0-b45c145a-02f1-4b2c-a030-6e01d4c0348f.pklz\n",
      "220414-17:02:25,290 nipype.workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ebeb48e209c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m              \u001b[0;34m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask_image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flglm.@mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m ])\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"execution\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"create_report\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%dT%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"execution\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"write_provenance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_wd\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Return wherever we were before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda-latest/envs/neuro/lib/python3.6/site-packages/nipype/pipeline/plugins/tools.py\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0;34m\"Workflow did not execute cleanly. \"\u001b[0m \u001b[0;34m\"Check log for details\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "glm.connect([(info, dg, [('sub', 'sub')]), # get sub info to feed into data grabber\n",
    "             (dg, ds, [(('motion', printSubPath), # print the path for saving data to (i.e. sub-0x/ses-0x)\n",
    "                         'container')]),\n",
    "             (dg, get_onsets, [('onsets', 'input_files')]), # get the onsets for each run into a single set of bunches\n",
    "             (dg, gunzip_func, [('func', 'in_file')]), # unzip t2\n",
    "             (dg, gunzip_mask, [('mask', 'in_file')]), # unzip masks\n",
    "             (gunzip_func, smooth, [('out_file', 'in_files')]), # smooth data\n",
    "             (smooth, ds, [('smoothed_files', 'data.@smooth')]), # save smoothed\n",
    "             (dg, get_tr, [('bjson', 'input_files')]), # get TR for model definition\n",
    "             (get_tr, model_spec, [('TR', 'time_repetition')]), # TR for model spec\n",
    "             (dg, model_spec, [('motion', 'realignment_parameters')]),\n",
    "             (get_onsets, model_spec, [('prt_output', 'subject_info')]),\n",
    "             (smooth, model_spec, [('smoothed_files', 'functional_runs')]),\n",
    "             (get_tr, level_1_design, [('TR', 'interscan_interval')]),\n",
    "             (model_spec, level_1_design, [('session_info', 'session_info')]),\n",
    "             (gunzip_mask, level_1_design, [('out_file', 'mask_image')]), # can it take 3 images? TBC - I think not\n",
    "             (level_1_design, estimate, [('spm_mat_file', 'spm_mat_file')]),\n",
    "             (estimate, ds, [('beta_images', 'flglm.@beta')]),\n",
    "             (estimate, ds, [('spm_mat_file', 'flglm.@des')]),\n",
    "             (estimate, ds, [('residual_image', 'flglm.@res')]),\n",
    "             (estimate, ds, [('mask_image', 'flglm.@mask')])\n",
    "])\n",
    "glm.run()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
