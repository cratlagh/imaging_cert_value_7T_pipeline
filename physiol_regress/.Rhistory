# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
#print(paste("CHECK values 1:nruns  = ", 1:nruns))
#print(paste0("CONTENTS e_nms = ", e_nms))
#Old.Man.Global <<- e_nms
#print("stop here")
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
#print(paste0("contents behav_dat: ", behav_dat))
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# contains all columns from both beh data files - so retain the ccw column for motor
# print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# adds cert/probaiblity column
#print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now combine with event timing data
# dat, evs, sub, sess, run, sub_folders, motor_sanity
# function(dat, evs, sub, sess, run, sub_folders, motor_sanity = FALSE)
# run line below to generate experimental onset SPM files
# events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
#print(paste0("The 1 below represents Run 1 of the file of interest; this is only applicable to the motor file generation"))
# run line below to generate motor sanity check SPM files
namePatt<-"_task-learnAtt_acq-TR1510_bold_"
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, motor_sanity=motor_sanity_on, sub, session, 1, data_dir, namePatt, SIMPLIFY = FALSE)
#print(paste0("CONTENT events_4_spm: ", events_4_spm))
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x, motor_sanity = motor_sanity_on))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) {p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=cert, y=rt, col=reward_type)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
if (sub < 10){
sub_str <- sprintf("sub-0%d", sub)
} else {
sub_str <- sprintf("sub-%d", sub)
}
ggsave(filename = paste(data_dir, sub_str, "/", "ses-02/", "beh/", sub_str, "_behavsum.pdf", sep=""),
plot = p, units = "cm", width = 20, height = 20)
}
list(dat_4_behav_analysis)
}
# Run function
# --------------------------------------------------------------------
dat <- mapply(get_spm_onsets_and_data_4_analysis, sub = sub_nums, runN = runs, MoreArgs = list(data_dir = data_dir, verbose = TRUE))
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
################################################################################
# SPM control panel -> uncomment which version to create
# create motor sanity check SPM files
motor_sanity_on = TRUE
# create experiment SPM files
#motor_sanity_on = FALSE
################################################################################
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE))
#sub_nums <- sub_nums[1]
runs <- rep(3, length(sub_nums)) # this needs to be a vector of length sub_nums, with the corresponding number of runs we
runs[which(sub_nums == 137)] <- 2
# have for that participant
session = 2
TR = 1510
save_alldat_loc <- "/data/VALCERT/derivatives/beh_shaped_data_analysis" # NOTE - THIS NEEDS TO BE DEFINED - WHERE SHALL WE SAVE THE BEHAV DF?
data_dir = '/data/VALCERT/derivatives/fmriprep/'
# beh data path pattern
#beh_patt = "sub-[0-9]*"
# sub_folders <- beh_data_path_patt(data_dir, beh_patt)
# sub_folders
#
# looky<-json_file_list(1,sub_folders)
# looky[[1]]$resp_order
# file_names <- beh_data_file_patt(sub_folders[1],beh_patt)
# file_names
# example: "resp_key": "clockwise: j, anticlockwise: f",
#resp_map_counter(1,2,data_dir)
count = 0
Old.Man.Global = "" # what's this variable?
# Define function to print onsets
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis <- function(sub, runN, data_dir, verbose){
# for a single subject, get mri behaviour details and save the outputs to
# a json glm file for use with spm (one json file per run)
# return a dataframe containing the behavioural data concatenated across
# the runs for that participant, ready for further analysis
# Args:
# -- sub [int]: the subject number to be analysed
# -- runN [int]: how many runs do we have for that subject?
# -- data_dir [str]: where do you want outputs to be saved? e.g. '~/Insync/tmp-data/full-exp-pilot-raw'
#                      functions assume that this is the top level for where sub-x/ses-x/beh lives
# -- verbose [TRUE or FALSE]: return plot of subject data?
# Returns:
# -- json file for each run containing names, onsets and durations for defining glm in spm
# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
#print(paste("CHECK values 1:nruns  = ", 1:nruns))
#print(paste0("CONTENTS e_nms = ", e_nms))
#Old.Man.Global <<- e_nms
#print("stop here")
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
#print(paste0("contents behav_dat: ", behav_dat))
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# contains all columns from both beh data files - so retain the ccw column for motor
# print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# adds cert/probaiblity column
#print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now combine with event timing data
# dat, evs, sub, sess, run, sub_folders, motor_sanity
# function(dat, evs, sub, sess, run, sub_folders, motor_sanity = FALSE)
# run line below to generate experimental onset SPM files
# events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
#print(paste0("The 1 below represents Run 1 of the file of interest; this is only applicable to the motor file generation"))
# run line below to generate motor sanity check SPM files
namePatt<-"_task-learnAtt_acq-TR1510_bold_"
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, motor_sanity=motor_sanity_on, sub, session, 1, data_dir, namePatt, SIMPLIFY = FALSE)
#print(paste0("CONTENT events_4_spm: ", events_4_spm))
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x, motor_sanity = motor_sanity_on))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) {p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=cert, y=rt, col=reward_type)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
if (sub < 10){
sub_str <- sprintf("sub-0%d", sub)
} else {
sub_str <- sprintf("sub-%d", sub)
}
ggsave(filename = paste(data_dir, sub_str, "/", "ses-02/", "beh/", sub_str, "_behavsum.pdf", sep=""),
plot = p, units = "cm", width = 20, height = 20)
}
list(dat_4_behav_analysis)
}
# Run function
# --------------------------------------------------------------------
dat <- mapply(get_spm_onsets_and_data_4_analysis, sub = sub_nums, runN = runs, MoreArgs = list(data_dir = data_dir, verbose = TRUE))
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
################################################################################
# SPM control panel -> uncomment which version to create
# create motor sanity check SPM files
motor_sanity_on = TRUE
# create experiment SPM files
#motor_sanity_on = FALSE
################################################################################
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE))
#sub_nums <- sub_nums[1]
runs <- rep(3, length(sub_nums)) # this needs to be a vector of length sub_nums, with the corresponding number of runs we
runs[which(sub_nums == 137)] <- 2
# have for that participant
session = 2
TR = 1510
save_alldat_loc <- "/data/VALCERT/derivatives/beh_shaped_data_analysis" # NOTE - THIS NEEDS TO BE DEFINED - WHERE SHALL WE SAVE THE BEHAV DF?
data_dir = '/data/VALCERT/derivatives/fmriprep/'
# beh data path pattern
#beh_patt = "sub-[0-9]*"
# sub_folders <- beh_data_path_patt(data_dir, beh_patt)
# sub_folders
#
# looky<-json_file_list(1,sub_folders)
# looky[[1]]$resp_order
# file_names <- beh_data_file_patt(sub_folders[1],beh_patt)
# file_names
# example: "resp_key": "clockwise: j, anticlockwise: f",
#resp_map_counter(1,2,data_dir)
count = 0
Old.Man.Global = "" # what's this variable?
# Define function to print onsets
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis <- function(sub, runN, data_dir, verbose){
# for a single subject, get mri behaviour details and save the outputs to
# a json glm file for use with spm (one json file per run)
# return a dataframe containing the behavioural data concatenated across
# the runs for that participant, ready for further analysis
# Args:
# -- sub [int]: the subject number to be analysed
# -- runN [int]: how many runs do we have for that subject?
# -- data_dir [str]: where do you want outputs to be saved? e.g. '~/Insync/tmp-data/full-exp-pilot-raw'
#                      functions assume that this is the top level for where sub-x/ses-x/beh lives
# -- verbose [TRUE or FALSE]: return plot of subject data?
# Returns:
# -- json file for each run containing names, onsets and durations for defining glm in spm
# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
#print(paste("CHECK values 1:nruns  = ", 1:nruns))
#print(paste0("CONTENTS e_nms = ", e_nms))
#Old.Man.Global <<- e_nms
#print("stop here")
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
#print(paste0("contents behav_dat: ", behav_dat))
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# contains all columns from both beh data files - so retain the ccw column for motor
# print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# adds cert/probaiblity column
#print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now combine with event timing data
# dat, evs, sub, sess, run, sub_folders, motor_sanity
# function(dat, evs, sub, sess, run, sub_folders, motor_sanity = FALSE)
# run line below to generate experimental onset SPM files
# events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
#print(paste0("The 1 below represents Run 1 of the file of interest; this is only applicable to the motor file generation"))
# run line below to generate motor sanity check SPM files
namePatt<-"_task-learnAtt_acq-TR1510_bold_"
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, motor_sanity=motor_sanity_on, sub, session, 1, data_dir, namePatt, SIMPLIFY = FALSE)
#print(paste0("CONTENT events_4_spm: ", events_4_spm))
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x, motor_sanity = motor_sanity_on))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) {p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=cert, y=rt, col=reward_type)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
if (sub < 10){
sub_str <- sprintf("sub-0%d", sub)
} else {
sub_str <- sprintf("sub-%d", sub)
}
ggsave(filename = paste(data_dir, sub_str, "/", "ses-02/", "beh/", sub_str, "_behavsum.pdf", sep=""),
plot = p, units = "cm", width = 20, height = 20)
}
list(dat_4_behav_analysis)
}
# Run function
# --------------------------------------------------------------------
dat <- mapply(get_spm_onsets_and_data_4_analysis, sub = sub_nums, runN = runs, MoreArgs = list(data_dir = data_dir, verbose = TRUE))
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
################################################################################
# SPM control panel -> uncomment which version to create
# create motor sanity check SPM files
motor_sanity_on = TRUE
# create experiment SPM files
#motor_sanity_on = FALSE
################################################################################
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE))
#sub_nums <- sub_nums[1]
runs <- rep(3, length(sub_nums)) # this needs to be a vector of length sub_nums, with the corresponding number of runs we
runs[which(sub_nums == 137)] <- 2
# have for that participant
session = 2
TR = 1510
save_alldat_loc <- "/data/VALCERT/derivatives/beh_shaped_data_analysis" # NOTE - THIS NEEDS TO BE DEFINED - WHERE SHALL WE SAVE THE BEHAV DF?
data_dir = '/data/VALCERT/derivatives/fmriprep/'
# beh data path pattern
#beh_patt = "sub-[0-9]*"
# sub_folders <- beh_data_path_patt(data_dir, beh_patt)
# sub_folders
#
# looky<-json_file_list(1,sub_folders)
# looky[[1]]$resp_order
# file_names <- beh_data_file_patt(sub_folders[1],beh_patt)
# file_names
# example: "resp_key": "clockwise: j, anticlockwise: f",
#resp_map_counter(1,2,data_dir)
count = 0
Old.Man.Global = "" # what's this variable?
# Define function to print onsets
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis <- function(sub, runN, data_dir, verbose){
# for a single subject, get mri behaviour details and save the outputs to
# a json glm file for use with spm (one json file per run)
# return a dataframe containing the behavioural data concatenated across
# the runs for that participant, ready for further analysis
# Args:
# -- sub [int]: the subject number to be analysed
# -- runN [int]: how many runs do we have for that subject?
# -- data_dir [str]: where do you want outputs to be saved? e.g. '~/Insync/tmp-data/full-exp-pilot-raw'
#                      functions assume that this is the top level for where sub-x/ses-x/beh lives
# -- verbose [TRUE or FALSE]: return plot of subject data?
# Returns:
# -- json file for each run containing names, onsets and durations for defining glm in spm
# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
#print(paste("CHECK values 1:nruns  = ", 1:nruns))
#print(paste0("CONTENTS e_nms = ", e_nms))
#Old.Man.Global <<- e_nms
#print("stop here")
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
#print(paste0("contents behav_dat: ", behav_dat))
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# contains all columns from both beh data files - so retain the ccw column for motor
# print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# adds cert/probaiblity column
#print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now combine with event timing data
# dat, evs, sub, sess, run, sub_folders, motor_sanity
# function(dat, evs, sub, sess, run, sub_folders, motor_sanity = FALSE)
# run line below to generate experimental onset SPM files
# events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
#print(paste0("The 1 below represents Run 1 of the file of interest; this is only applicable to the motor file generation"))
# run line below to generate motor sanity check SPM files
namePatt<-"_task-learnAtt_acq-TR1510_bold_"
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, motor_sanity=motor_sanity_on, sub, session, 1, data_dir, namePatt, SIMPLIFY = FALSE)
#print(paste0("CONTENT events_4_spm: ", events_4_spm))
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x, motor_sanity = motor_sanity_on))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) {p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=cert, y=rt, col=reward_type)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
if (sub < 10){
sub_str <- sprintf("sub-0%d", sub)
} else {
sub_str <- sprintf("sub-%d", sub)
}
ggsave(filename = paste(data_dir, sub_str, "/", "ses-02/", "beh/", sub_str, "_behavsum.pdf", sep=""),
plot = p, units = "cm", width = 20, height = 20)
}
list(dat_4_behav_analysis)
}
# Run function
# --------------------------------------------------------------------
dat <- mapply(get_spm_onsets_and_data_4_analysis, sub = sub_nums, runN = runs, MoreArgs = list(data_dir = data_dir, verbose = TRUE))
FD_results
setwd("~/neurodesktop-storage/imaging_cert_value_7T_pipeline/physiol_regress")
sub_nums<-read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE)
colnames(sub_nums)<-("part_nums")
# add a leading zero to subject numbers below sub-10
sub_nums$part_nums<-ifelse(as.numeric(sub_nums$part_nums)<10,paste0("0",sub_nums$part_nums),sub_nums$part_nums)
# define file name pattern including path, allowing for changing number values
# set ses to ses-02 here as it never changes in the current dataset
filepattern <- "/data/VALCERT/derivatives/fmriprep/sub-%s/ses-02/func/sub-%s_ses-02_task-attlearn_run-%s_desc-confounds_timeseries.tsv"
# define all potential run numbers as characters
runs <- c("1","2","3")
# create empty dataframe to hold participant number, run number, and calculated percentage values
FD_results <- data.frame(part_num = character(0), run = character(0), perc = numeric(0))
# set how many times to check for missing file:
# in this version, the first iteration is the default pattern, the subsequent
# 2 interations add one leading zero, and two leadings zeros respectively to
# the run- parameter in the file name
max_iterations = 3 # original + one and two leading zeros
# set the FD censoring threshold in mm
censor_threshold = 0.2
# return runs that are >= n% FD threshold breaking
perc_threshold = 60
# for loop to cycle through all participants in the sub_nums dataframe
for(curr_sub in 1:length(sub_nums$part_nums)){
# for loop to cycle through specified runs
for (curr_run in 1:length(runs)){
# set reiterate to 0; used for searching for missing files again with added leading zero/s
reiterate = 0
# initial file name pattern prior to no match being found
# plug-in current sub number into foldefr path and into file name, and plug-in run number into file name
findFile = sprintf(filepattern, sub_nums$part_nums[curr_sub], sub_nums$part_nums[curr_sub], runs[curr_run])
# while loop where it retries
while (reiterate < max_iterations){
# try to execute the code below but catch if it fails:
# if no file match is found the specified error code is printed to terminal
# and upon retry the reiterate value will force a change to the file name pattern
# where n leading zeros are added to the run- parameter
tryCatch({
# can automate this code to do n leading zeros checks for run... however, gets into mental loop territory
if (reiterate == 1){
# add one leading zero to run-n
findFile = sprintf(filepattern, sub_nums$part_nums[curr_sub], sub_nums$part_nums[curr_sub], sprintf("%02d",as.integer(runs[curr_run])))
# tell user that we are retrying to find the file using the printed pattern and explain what is different
print(paste("Will try file pattern", findFile, "with 1 leading zeros in run-n parameter"))
}
if (reiterate == 2){
findFile =sprintf(filepattern, sub_nums$part_nums[curr_sub], sub_nums$part_nums[curr_sub], sprintf("%03d",as.integer(runs[curr_run])))
print(paste("Will try file pattern", findFile, "with 2 leadings zeros in run-n parameter"))
}
# increment reiterate value here in case the file is not found and thus force file pattern change as above
reiterate = reiterate +1
# uncomment below for sanity checks:
# print(paste("Value of reiterate = ", reiterate))
# print(paste("contents findFile: ", findFile))
# pass file name matching pattern in findFile (pattern dependent upon above code as explained)
mot_phys_reg <- read.table(findFile, header = TRUE, sep = "\t")
# pass all values in the framewise_displacement in FD
FD<-mot_phys_reg$framewise_displacement
# turn any "n/a" into "0"
FD_na_rid<-ifelse(FD=="n/a","0",FD)
# count how many items in FD_na_rid are greater than or equal to the specified censor threshold
FD_exceeded<-sum(as.numeric(FD_na_rid)>=censor_threshold)
# calculate percentage of total number of rows:
# divide number of FD exceeding the censor threshold by 1% of the total number of items
# which will return the % of FDs exceeding the specified threshold
percentage_FD_exceeded <- FD_exceeded/(length(FD_na_rid)*.01)
#percentage_FD_exceeded
# pass current subject, run, and the calculated % of FD exceeding specified censor threshold into a single row dataframe
curr_details = data.frame(part_num = sub_nums$part_nums[curr_sub], run = runs[curr_run], perc = percentage_FD_exceeded)
# append/bind the above single row dataframe to FD_results dataframe
FD_results <- rbind(FD_results,curr_details)
# if all of the above ran without issue, break the while loop
break
# if there was an issue above (no matching file found)
# run code below explaining error
}, error = function(err){
# print information about file not found
print(paste("File", findFile, "not found..."))
# after this the while loop wil try again by adding a leading zero.
# It will only do this twice for 0n, and 00n, before moving onto the
# next run/participant
} # end of error
) # end of tryCatch
} # end of while loop used to reattempt file search with added leading zero/s
} # end of sub_runs for loop
} # end of sub_nums$part_nums for loop
# all results
FD_results
perc60 <-FD_results[FD_results$perc>=perc_threshold,]
perc60
