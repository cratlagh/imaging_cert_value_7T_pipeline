remove.packages("rstan")
if (file.exists(".RData")) file.remove("RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library(rstan)
example(stan_model, package="rstan", run.dontrun = TRUE)
install.packages("brms")
setwd("~/neurodesktop-storage/imaging_cert_value_7T_pipeline/behav2onsets")
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
sub_nums <- t(read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE))
sub_nums <- sub_nums[1]
runs <- rep(3, length(sub_nums)) # this needs to be a vector of length sub_nums, with the corresponding number of runs we
runs[which(sub_nums == 137)] <- 2
# have for that participant
session = 2
TR = 1510
save_alldat_loc <- "/data/VALCERT/derivatives/beh_shaped_data_analysis" # NOTE - THIS NEEDS TO BE DEFINED - WHERE SHALL WE SAVE THE BEHAV DF?
data_dir = '/data/VALCERT/derivatives/fmriprep/'
count = 0
Old.Man.Global = "" # what's this variable?
sub = 1
runN = 1
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
dat <- all_behav_info[[1]]
evs <- event_timings[[1]]
#                    and 'allocate_conditions_on_d'
# -- evs [dataframe] event timings from the run matching dat, acquired using 'get_event_times_data'
# -- motor_sanity [TRUE/FALSE] when TRUE, pulls data for motor response left hand vs right hand; when FALSE pulls data for task
# -- sub [dataframe] subject numbers pulled from csv file
# -- sess [integer] session number of interest
# -- run [integer] hardcoded as '1' given response mapping is the same for a given participant across n runs
# -- sub_folders [string] data directory path
# -- namePatt [string] file name pattern
# Returns:
# list of names, onsets and durations of each condition, for use with make_spm_event_files
sess_data <- inner_join(dat, evs[evs$event == "value cues",], by = "t")
sess_data
# making a variable that will tell me which value
# was on the left and which was on the right
sess_data$left_col <- as.factor(sess_data$left_col)
head(sess_data)
levels(sess_data$left_col) <- c("l", "h")
head(sess_data)
sess_data$right_col <- as.factor(sess_data$right_col)
levels(sess_data$right_col) <- c("l", "h")
head(sess_data)
sess_data <- sess_data %>% mutate(val_config = paste(left_col, right_col, sep=""))
head(sess_data)
tail(sess_data)
sess_data %>% filter(val_config == "hl")
value_cue_types <- unique(sess_data$val_config)
head(value_cue_types)
names = sort(as.vector(outer(tgt_locs, spatial_cue_types, paste, sep="_")))
tgt_locs <- c("left", "right")
spatial_cue_types <- c(".5", ".8")
names = sort(as.vector(outer(tgt_locs, spatial_cue_types, paste, sep="_")))
names = sort(as.vector(outer(names, value_cue_types, paste, sep = "_")))
names
head(sess_data)
onsets <- mapply(function(x, y, z) sess_data$rel.onset[sess_data$loc == x & sess_data$cert == y & sess_data$val_config == z],
x = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[1,], # tgt location (factor 1)
y = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[2,], # cue prob condition (factor 2)
z = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[3,], # rel val cond (factor 3)
SIMPLIFY = FALSE)
durations <- lapply(onsets, function(x) rep(0, length(x)))
onsets
# this will allow us to pull out correct tgt locations from the data - i.e. the
# entries match 'tgt_locs'
sess_data$loc <- as.factor(sess_data$loc) # where the tgt appeared
levels(sess_data$loc) <- c("left", "right")
onsets <- mapply(function(x, y, z) sess_data$rel.onset[sess_data$loc == x & sess_data$cert == y & sess_data$val_config == z],
x = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[1,], # tgt location (factor 1)
y = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[2,], # cue prob condition (factor 2)
z = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[3,], # rel val cond (factor 3)
SIMPLIFY = FALSE)
durations <- lapply(onsets, function(x) rep(0, length(x)))
onsets
names
#### wrapper code to use the functions defined in event_analysis_functions.R
#### to get trial data in relevant format to define glms using spm12 functionality
# K. Garner, 2020
# --------------------------------------------------------------------
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
################################################################################
# SPM control panel -> uncomment which version to create
# create motor sanity check SPM files
#motor_sanity_on = TRUE
# create experiment SPM files
motor_sanity_on = FALSE
################################################################################
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/data/VALCERT/derivatives/complete-participants.csv', header = FALSE))
#sub_nums <- sub_nums[1]
runs <- rep(3, length(sub_nums)) # this needs to be a vector of length sub_nums, with the corresponding number of runs we
runs[which(sub_nums == 137)] <- 2
# have for that participant
session = 2
TR = 1510
save_alldat_loc <- "/data/VALCERT/derivatives/beh_shaped_data_analysis" # NOTE - THIS NEEDS TO BE DEFINED - WHERE SHALL WE SAVE THE BEHAV DF?
data_dir = '/data/VALCERT/derivatives/fmriprep/'
# beh data path pattern
#beh_patt = "sub-[0-9]*"
# sub_folders <- beh_data_path_patt(data_dir, beh_patt)
# sub_folders
#
# looky<-json_file_list(1,sub_folders)
# looky[[1]]$resp_order
# file_names <- beh_data_file_patt(sub_folders[1],beh_patt)
# file_names
# example: "resp_key": "clockwise: j, anticlockwise: f",
#resp_map_counter(1,2,data_dir)
count = 0
# Define function to print onsets
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis <- function(sub, runN, data_dir, verbose){
# for a single subject, get mri behaviour details and save the outputs to
# a json glm file for use with spm (one json file per run)
# return a dataframe containing the behavioural data concatenated across
# the runs for that participant, ready for further analysis
# Args:
# -- sub [int]: the subject number to be analysed
# -- runN [int]: how many runs do we have for that subject?
# -- data_dir [str]: where do you want outputs to be saved? e.g. '~/Insync/tmp-data/full-exp-pilot-raw'
#                      functions assume that this is the top level for where sub-x/ses-x/beh lives
# -- verbose [TRUE or FALSE]: return plot of subject data?
# Returns:
# -- json file for each run containing names, onsets and durations for defining glm in spm
# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
nruns <- runN
# need to write version of below for motor files
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
#print(paste0("e_nms STRAIGHT after get_mri_fnames = ", e_nms))
# e_nms only ever has one sub at a time but all over their relevant files
rownames(e_nms) <- sub # building row names based using sub numbers
colnames(e_nms) <- 1:nruns # building column names using run numbers
#print(paste("CHECK values 1:nruns  = ", 1:nruns))
#print(paste0("CONTENTS e_nms = ", e_nms))
#print("stop here")
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
#print(paste0("contents behav_dat: ", behav_dat))
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
#print(paste0("contents task_dat: ", task_dat))
# does contain ccw column
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# contains all columns from both beh data files - so retain the ccw column for motor
# print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# adds cert/probaiblity column
#print(paste0("CONTENT all_behav_info: ", all_behav_info))
# now combine with event timing data
# dat, evs, sub, sess, run, sub_folders, motor_sanity
# function(dat, evs, sub, sess, run, sub_folders, motor_sanity = FALSE)
# run line below to generate experimental onset SPM files
# events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
#print(paste0("The 1 below represents Run 1 of the file of interest; this is only applicable to the motor file generation"))
# run line below to generate motor sanity check SPM files
namePatt<-"_task-learnAtt_acq-TR1510_bold_"
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, motor_sanity=motor_sanity_on, sub, session, 1, data_dir, namePatt, SIMPLIFY = FALSE)
#print(paste0("CONTENT events_4_spm: ", events_4_spm))
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x, motor_sanity = motor_sanity_on))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) {p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=cert, y=rt, col=reward_type)) +
geom_violin(alpha = 0.5) +
geom_boxplot(width = 0.1) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
if (sub < 10){
sub_str <- sprintf("sub-0%d", sub)
} else {
sub_str <- sprintf("sub-%d", sub)
}
ggsave(filename = paste(data_dir, sub_str, "/", "ses-02/", "beh/", sub_str, "_behavsum.pdf", sep=""),
plot = p, units = "cm", width = 20, height = 20)
}
list(dat_4_behav_analysis)
}
# Run function
# --------------------------------------------------------------------
dat <- mapply(get_spm_onsets_and_data_4_analysis, sub = sub_nums, runN = runs, MoreArgs = list(data_dir = data_dir, verbose = FALSE))
