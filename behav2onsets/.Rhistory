setwd("~/scratch/imaging_cert_value_7T_pipeline/behav2onsets")
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/clusterdata/uqkgarn1/scratch/data/complete-participants.csv', header = FALSE))
# tmp single sub for pilot data
sub_nums = sub_nums[1]
session = 2
nruns = 3
TR = 1510
data_dir = '/clusterdata/uqkgarn1/scratch/data'
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
sub
sub = sub_nums
TR
nruns
e_nms = get_mri_fnames(sub, fn, TR, nr
uns, "beh", data_dir)
rownames(e_nms) <- sub
colnames(e_nms) <- 1:nruns
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
e_nms
rownames(e_nms) <- sub
colnames(e_nms) <- 1:nruns
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = e_nms[1]
fn
event.times = read.table(file = fn, sep = '\t', header = TRUE)
# if required, chop off everything prior to the onset of the first dummy scan
# see https://github.com/kel-github/imaging-cert-reward-att-task-code/blob/master/sess-mri-exp/run_mri_session.m
# for code that shows that trimming the first pulse value is necessary, as it is a dummy
# value used to get the event file writing started
n.pre = which(event.times$event=="dummy scan")[1]-1
# what is the impact for timing?
if (any(as.logical(n.pre))) event.times = event.times[-c(1:n.pre),]
event.times
head(event.times)
fn
e_nms
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
e_nms
rownames(e_nms) <- sub
colnames(e_nms) <- 1:nruns
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
task_dat
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
head(all_behav_info)
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
dat = all_behav_info[[1]]
evs = event_timings[[1]]
# each condition of interest.
# conditions of interest are:
# Left| Right tgt x Spatial Cue (.2, .5, .8) x Value Cues
# Assuming modelling via delta stick from onset of value cues
# Args:
# -- dat [dataframe] produced using a combination of get_mri_dat (on task and behav data)
#                    and 'allocate_conditions_on_d'
# -- evs [dataframe] event timings from the run matching dat, acquired using 'get_event_times_data'
# Returns:
# list of names, onsets and durations of each condition, for use with make_spm_event_files
sess_data <- inner_join(dat, evs[evs$event == "value cues",], by = "t")
head(sess_data)
View(sess_data)
tgt_locs <- c("left", "right")
spatial_cue_types <- unique(sess_data$cert)
value_cue_types <- unique(sess_data$reward_type)
names = sort(as.vector(outer(tgt_locs, spatial_cue_types, paste, sep="_")))
names = sort(as.vector(outer(names, value_cue_types, paste, sep = "_")))
names
nleft <- length(names)/2
nspat <- nleft/3
nval <- length(value_cue_types)
sess_data$loc <- as.factor(sess_data$loc)
levels(sess_data$loc) <- c("left", "right")
# remove error trials
sess_data <- sess_data %>% filter(resp == 1)
tgt_locs <- c("left", "right")
spatial_cue_types
sort(unique(sess_data$cert))
sort(unique(sess_data$cert))+1
levels(sess_data$cert)
levels(sess_data$cert)[levels(sess_data$cert) != ".2"]
spatial_cue_types <- levels(sess_data$cert)[levels(sess_data$cert) != ".2"]
value_cue_types <- unique(sess_data$reward_type)
names = sort(as.vector(outer(tgt_locs, spatial_cue_types, paste, sep="_")))
names = sort(as.vector(outer(names, value_cue_types, paste, sep = "_")))
names
nleft <- length(names)/2
nspat <- nleft/length(spatial_cue_types)
nspat
nval <- length(value_cue_types)
sess_data$loc <- as.factor(sess_data$loc)
levels(sess_data$loc) <- c("left", "right")
onsets <- mapply(function(x, y, z) sess_data$rel.onset[sess_data$loc == x & sess_data$cert == y & sess_data$reward_type == z],
x = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[1,],
y = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[2,],
z = sapply(1:length(names), function(x) str_split(names[[x]], "_")[[1]])[3,],
SIMPLIFY = FALSE)
onsets
durations <- lapply(onsets, function(x) rep(0, length(x)))
out <- list(names, onsets, durations)
View(out)
names(out) <- c("names", "onsets", "durations")
out
rm(list=ls())
# load packages and define session variables
library(tidyverse)
library(jsonlite)
source('events_analysis_functions.R')
# get list of subject numbers who did fmri task
sub_nums <- t(read.csv('/clusterdata/uqkgarn1/scratch/data/complete-participants.csv', header = FALSE))
# tmp single sub for pilot data
sub_nums = sub_nums[1]
session = 2
nruns = 3
TR = 1510
data_dir = '/clusterdata/uqkgarn1/scratch/data'
# Define function to print onsets
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis <- function(sub, data_dir, verbose){
# for a single subject, get mri behaviour details and save the outputs to
# a json glm file for use with spm (one json file per run)
# return a dataframe containing the behavioural data concatenated across
# the runs for that participant, ready for further analysis
# Args:
# -- sub [int]: the subject number to be analysed
# -- data_dir [str]: where do you want outputs to be saved? e.g. '~/Insync/tmp-data/full-exp-pilot-raw'
#                      functions assume that this is the top level for where sub-x/ses-x/beh lives
# -- verbose [TRUE or FALSE]: return plot of subject data?
# Returns:
# -- json file for each run containing names, onsets and durations for defining glm in spm
# -- dat_4_behav_analysis [dataframe]: dataframe containing the behavioural data
#                                      for that participant for further analysis
# -- densities for reward cond x cueing effect, if verbose is TRUE
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_events.tsv"
e_nms = get_mri_fnames(sub, fn, TR, nruns, "beh", data_dir)
rownames(e_nms) <- sub
colnames(e_nms) <- 1:nruns
# now get event details per run returned as a list
event_timings <- lapply(e_nms, get_event_times_data)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls.tsv"
behav_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns)
fn = "_ses-02_task-learnAtt_acq-TR%d_run-0%d_trls_tbl.txt"
task_dat <- get_mri_dat(sub, session, data_dir, "beh", fn, TR, nruns, sep=",")
for (i in 1:length(task_dat)) names(task_dat[[i]])[names(task_dat[[i]]) == "trial_num"] = "t"
all_behav_info <- mapply(function(x,y) inner_join(x, y, by = c("sub", "sess", "t", "run")), behav_dat, task_dat, SIMPLIFY = FALSE)
# now I have all the behavioural info for each run, I can first
# allocate the conditions to each run's data, then combine with the event timing
# data and write the spm glm json files
# I will also be ready to rbind the data from across the runs for
# behavioural analysis
all_behav_info <- lapply(all_behav_info, allocate_conditions_on_d)
# now combine with event timing data
events_4_spm <- mapply(match_behaviour_to_event_timings, all_behav_info, event_timings, SIMPLIFY = FALSE)
# now write to json files
lapply(1:length(events_4_spm), function(x) write_json_4_spm(events_4_spm[[x]], fpath=data_dir, sub, x))
# now rbind behavioural data and plot
dat_4_behav_analysis <- do.call(rbind, all_behav_info)
if(verbose) p = dat_4_behav_analysis %>% filter(resp == 1) %>% ggplot(aes(x=rt, group=reward_type, col=reward_type)) +
geom_density(fill="white", alpha = 0.5) +
facet_wrap(~reward_type) +
ggtitle(paste("sub", dat_4_behav_analysis$sub[1]))
list(dat_4_behav_analysis, p)
}
# Run function
# --------------------------------------------------------------------
get_spm_onsets_and_data_4_analysis(sub_nums[1], data_dir, TRUE)
data_dir
